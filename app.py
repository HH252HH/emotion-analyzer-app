# ==========================================================
# ğŸ§  Emotion AI Pro â€” NeuroVision (Enterprise + Auto Language)
# ğŸ¨ Radical UI + Stable Fixes + AR/EN Support
# ==========================================================

# ==============================
# ğŸ“¦ Imports (UNCHANGED + langdetect)
# ==============================
import streamlit as st
import requests
import os
from dotenv import load_dotenv
from PIL import Image
import plotly.graph_objects as go
import assemblyai as aai
from openai import OpenAI
from io import BytesIO
import tempfile
from langdetect import detect

# ==========================================================
# ğŸ” API Keys
# ===========================================================
from dotenv import load_dotenv
import os
import streamlit as st
from openai import OpenAI

# ØªØ­Ù…ÙŠÙ„ .env Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·
load_dotenv()

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦Ø© (Ù…Ø­Ù„ÙŠ Ø£Ùˆ Ø³ÙŠØ±ÙØ±)
HUGGINGFACE_API_KEY = os.getenv("HUGGINGFACE_API_KEY")
ASSEMBLYAI_API_KEY = os.getenv("ASSEMBLYAI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ÙØ­Øµ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ
missing_keys = []

if not HUGGINGFACE_API_KEY:
    missing_keys.append("HUGGINGFACE_API_KEY")

if not ASSEMBLYAI_API_KEY:
    missing_keys.append("ASSEMBLYAI_API_KEY")

if not OPENAI_API_KEY:
    missing_keys.append("OPENAI_API_KEY")

if missing_keys:
    st.error(f"âŒ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù†Ø§Ù‚ØµØ©: {', '.join(missing_keys)}")
    st.info("ğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙÙŠ Environment Variables ÙÙŠ Ù…Ù†ØµØ© Ø§Ù„Ù†Ø´Ø±")
    st.stop()

# Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙŠÙ„ OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

# ==========================================================
# ğŸ¨ Page Config
# ==========================================================
st.set_page_config(
    page_title="Emotion AI Pro â€” NeuroVision",
    page_icon="ğŸ§ ",
    layout="wide"
)

# ==========================================================
# ğŸŒŒ UI Design
# ==========================================================
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;600;800&display=swap');

html, body, [class*="css"] {
    direction: rtl;
    font-family: 'Tajawal', sans-serif;
}

.stApp {
    background: radial-gradient(circle at 20% 30%, #1a1a2e, #0f3460, #16213e);
    background-size: 200% 200%;
    animation: moveBG 12s ease infinite;
}

@keyframes moveBG {
    0% {background-position: 0% 50%;}
    50% {background-position: 100% 50%;}
    100% {background-position: 0% 50%;}
}

.neo-card {
    background: rgba(255,255,255,0.05);
    border-radius: 25px;
    padding: 30px;
    backdrop-filter: blur(20px);
    border: 1px solid rgba(255,255,255,0.1);
    box-shadow: 0 8px 40px rgba(0,0,0,0.4);
    transition: 0.4s ease;
}

.neo-card:hover {
    transform: translateY(-6px);
    box-shadow: 0 20px 60px rgba(0,0,0,0.6);
}

.stButton>button {
    background: linear-gradient(135deg,#00c6ff,#0072ff);
    color:white;
    border:none;
    padding:14px 35px;
    border-radius:50px;
    font-size:18px;
    font-weight:600;
    transition:0.3s;
}

.stButton>button:hover {
    transform:scale(1.07);
    box-shadow:0 0 25px #00c6ff;
}

h1 {
    text-align:center;
    font-size:40px;
    font-weight:800;
    margin-bottom:30px;
}

.plotly-graph-div {
    border-radius:20px !important;
    overflow:hidden;
}
</style>
""", unsafe_allow_html=True)

# ==========================================================
# ğŸ§  HEADER
# ==========================================================
st.title("ğŸ§  Emotion AI Pro â€” NeuroVision")

# ==========================================================
# ğŸ“¥ INPUT SECTION
# ==========================================================
col1, col2 = st.columns(2)

with col1:
    st.markdown("<div class='neo-card'>", unsafe_allow_html=True)
    st.subheader("ğŸ“· ØªØ­Ù„ÙŠÙ„ ØªØ¹Ø§Ø¨ÙŠØ± Ø§Ù„ÙˆØ¬Ù‡")

    image_option = st.radio(
        "Ø§Ø®ØªØ± Ù…ØµØ¯Ø± Ø§Ù„ØµÙˆØ±Ø©:",
        ["Ø±ÙØ¹ ØµÙˆØ±Ø©", "Ø§Ù„ØªÙ‚Ø§Ø· Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§"],
        horizontal=True
    )

    image_bytes = None
    if image_option == "Ø±ÙØ¹ ØµÙˆØ±Ø©":
        uploaded_img = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=["jpg", "png"])
        if uploaded_img:
            image_bytes = uploaded_img.getvalue()
    else:
        camera_img = st.camera_input("Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø©")
        if camera_img:
            image_bytes = camera_img.getvalue()

    st.markdown("</div>", unsafe_allow_html=True)

with col2:
    st.markdown("<div class='neo-card'>", unsafe_allow_html=True)
    st.subheader("ğŸ¤ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„ØµÙˆØªÙŠØ©")

    audio_option = st.radio(
        "Ø§Ø®ØªØ± Ù…ØµØ¯Ø± Ø§Ù„ØµÙˆØª:",
        ["Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ", "ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†"],
        horizontal=True
    )

    audio_bytes = None
    if audio_option == "Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ":
        uploaded_audio = st.file_uploader(
            "Ø§Ø®ØªØ± ØµÙˆØª",
            type=["mp3", "wav", "m4a"]
        )
        if uploaded_audio:
            audio_bytes = uploaded_audio.getvalue()
    else:
        recorded_audio = st.audio_input("Ø³Ø¬Ù„ ØµÙˆØªÙƒ")
        if recorded_audio:
            audio_bytes = recorded_audio.getvalue()

    st.markdown("</div>", unsafe_allow_html=True)

# ==========================================================
# ğŸ“· IMAGE ANALYSIS
# ==========================================================
def analyze_image(image_bytes):
    try:
        API_URL = "https://router.huggingface.co/hf-inference/models/trpakov/vit-face-expression"
        headers = {
            "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
            "Content-Type": "application/octet-stream"
        }
        response = requests.post(API_URL, headers=headers, data=image_bytes, timeout=60)
        response.raise_for_status()
        result = response.json()

        if not isinstance(result, list) or len(result) == 0:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬Ù‡.")
            return None, None

        dominant = max(result, key=lambda x: x['score'])
        return result, dominant

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£: {e}")
        return None, None

# ==========================================================
# ğŸ¤ AUDIO ANALYSIS
# ==========================================================
def analyze_audio(audio_bytes):
    try:
        aai.settings.api_key = ASSEMBLYAI_API_KEY

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio_bytes)
            tmp_path = tmp.name

        config = aai.TranscriptionConfig(
            speech_models=["universal"],
            sentiment_analysis=True
        )

        transcript = aai.Transcriber().transcribe(tmp_path, config=config)
        os.remove(tmp_path)

        if transcript.status == aai.TranscriptStatus.error:
            st.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªÙØ±ÙŠØº: {transcript.error}")
            return None, None

        return transcript.text or "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ.", transcript.sentiment_analysis or []

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØµÙˆØª: {e}")
        return None, None

# ==========================================================
# ğŸŒ AUTO LANGUAGE DIAGNOSIS
# ==========================================================
def generate_diagnosis(image_emotion, audio_text):
    try:
        try:
            detected_lang = detect(audio_text) if audio_text.strip() else "ar"
        except:
            detected_lang = "ar"

        if detected_lang == "en":
            system_msg = "You are an expert emotional and psychological AI analyst."
            final_prompt = f"""
            Image emotion: {image_emotion}
            Speech text: {audio_text}

            Provide a psychological analysis including likelihood of:
            Anxiety - Stress - Depression
            With simple practical recommendations.
            """
        else:
            system_msg = "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ù†ÙØ³ÙŠ Ø¹Ø§Ø·ÙÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ."
            final_prompt = f"""
            Ø§Ù„Ø¹Ø§Ø·ÙØ© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©: {image_emotion}
            Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØª: {audio_text}

            Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ù‹Ø§ ÙŠØªØ¶Ù…Ù† Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ©:
            Ø§Ù„Ù‚Ù„Ù‚ - Ø§Ù„ØªÙˆØªØ± - Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨
            Ù…Ø¹ ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ© Ù…Ø¨Ø³Ø·Ø©.
            """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": final_prompt}
            ],
            temperature=0.7,
            max_tokens=800
        )

        return response.choices[0].message.content, detected_lang

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ OpenAI: {e}")
        return None, None

# ==========================================================
# ğŸš€ START ANALYSIS
# ==========================================================
if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ"):

    if image_bytes and audio_bytes:

        progress = st.progress(0)

        progress.progress(20)
        emotions, dominant = analyze_image(image_bytes)
        if not emotions:
            st.stop()

        progress.progress(50)
        text, sentiments = analyze_audio(audio_bytes)
        if text is None:
            st.stop()

        progress.progress(70)
        diagnosis, lang = generate_diagnosis(dominant["label"], text)

        progress.progress(100)

        # ================= RESULTS =================
        st.markdown("<div class='neo-card'>", unsafe_allow_html=True)
        colA, colB = st.columns(2)

        with colA:
            st.image(Image.open(BytesIO(image_bytes)), use_container_width=True)

        with colB:
            labels = [e["label"] for e in emotions]
            scores = [e["score"] for e in emotions]

            fig = go.Figure([go.Bar(x=labels, y=scores)])
            fig.update_layout(
                title="ØªØ­Ù„ÙŠÙ„ ØªØ¹Ø§Ø¨ÙŠØ± Ø§Ù„ÙˆØ¬Ù‡",
                template="plotly_dark"
            )
            st.plotly_chart(fig, use_container_width=True)

        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown("<div class='neo-card'>", unsafe_allow_html=True)
        st.subheader("ğŸ“Š Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
        st.info(f"ğŸŒ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' if lang == 'ar' else 'English'}")
        st.write(diagnosis)
        st.markdown("</div>", unsafe_allow_html=True)

    else:
        st.warning("âš  ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØ±Ø© ÙˆØµÙˆØª Ø£ÙˆÙ„Ø§Ù‹.")